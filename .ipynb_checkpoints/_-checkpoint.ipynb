{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764b10b2-7007-4815-ac85-d19050dfd619",
   "metadata": {
    "id": "764b10b2-7007-4815-ac85-d19050dfd619"
   },
   "source": [
    "# **Preparation Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e976e-fc1e-4392-8883-615faa601537",
   "metadata": {
    "id": "006e976e-fc1e-4392-8883-615faa601537",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resize data ke ukuran 640px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7cafc-d235-4824-aa63-1d0695e24cda",
   "metadata": {
    "id": "9bd7cafc-d235-4824-aa63-1d0695e24cda",
    "outputId": "b9b050e0-67ed-4653-b9d2-327c4bc6744e"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (3.12.5) (Python 3.12.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'e:/Program_ayu/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "input_folder = 'dataset_pakaian/images'\n",
    "output_folder = 'dataset_pakaian/resize'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "size = 640\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img.thumbnail((size, size), Image.Resampling.LANCZOS)\n",
    "        new_img = Image.new('RGB', (size, size), (255, 255, 255))\n",
    "        paste_x = (size - img.width) // 2\n",
    "        paste_y = (size - img.height) // 2\n",
    "        new_img.paste(img, (paste_x, paste_y))\n",
    "        new_img.save(os.path.join(output_folder, filename))\n",
    "\n",
    "print(\"All images have been resized and saved to the output folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a1a2b-f140-42d7-8e3e-4a7716276120",
   "metadata": {
    "id": "d38a1a2b-f140-42d7-8e3e-4a7716276120",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Anotasi Citra dari .xml ke .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd89b0-8ff9-4414-a3e1-fffdc17f4cdb",
   "metadata": {
    "id": "02dd89b0-8ff9-4414-a3e1-fffdc17f4cdb",
    "outputId": "596c62b1-33c4-4472-abec-7afaa9f49412"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (3.12.5) (Python 3.12.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'e:/Program_ayu/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!python xml2txt.py --annotations_path dataset_pakaian/annotations --labels_path dataset_pakaian/labels --classes \"atasan_sesuai=0,atasan_tidak_sesuai=1,bawahan_sesuai=2,bawahan_tidak_sesuai=3,alas_kaki_sesuai=4,alas_kaki_tidak_sesuai=5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5ab4c-d6db-440b-b76a-d3d7413cbc60",
   "metadata": {
    "id": "d4b5ab4c-d6db-440b-b76a-d3d7413cbc60",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cek Jumlah File Sebelum Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3055e9d-cdb1-4071-9648-80afa022fc90",
   "metadata": {
    "id": "c3055e9d-cdb1-4071-9648-80afa022fc90",
    "outputId": "03c2720c-5959-40ea-d916-86902b5dc72a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory: str) -> int:\n",
    "    try:\n",
    "        return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing directory {directory}: {e}\")\n",
    "        return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    resize = 'dataset_pakaian/resize'\n",
    "    num_resize = count_files(resize)\n",
    "    print(f\"Number of files in train directory: {num_resize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e70cf-573d-4704-b0e4-be1409cb9eae",
   "metadata": {
    "id": "e78e70cf-573d-4704-b0e4-be1409cb9eae",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c422768a-710b-4da9-8649-15f1665927bf",
   "metadata": {
    "id": "c422768a-710b-4da9-8649-15f1665927bf",
    "outputId": "d42680da-e377-4fbb-9fd0-e39f535f04c4"
   },
   "outputs": [],
   "source": [
    "!python dataset_preparation.py --data_path ./ --train_path dataset/train --valid_path dataset/val --split_ratio 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b378750",
   "metadata": {},
   "source": [
    "## Augmentasi Data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b0ac1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data_augmentation.py --train_path dataset/train --num_augmentations 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a26a8f",
   "metadata": {},
   "source": [
    "## Tampil Citra Augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7177845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory path\n",
    "directory = 'dataset/train/images'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Select the first 5 image paths from the directory\n",
    "image_paths = [os.path.join(directory, file) for file in files[:6]]\n",
    "\n",
    "# Define a function to load and plot images\n",
    "def plotImages(image_paths):\n",
    "    fig, axes = plt.subplots(1, len(image_paths), figsize=(30, 20))\n",
    "    for img_path, ax in zip(image_paths, axes):\n",
    "        # Load image using cv2\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB (opencv uses BGR by default)\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotImages function to display the images\n",
    "plotImages(image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e4c32",
   "metadata": {},
   "source": [
    "# Train lr 0.001 with yolov8n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a952d47",
   "metadata": {},
   "source": [
    "## Epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3gSMYxUyCC_i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gSMYxUyCC_i",
    "outputId": "0e7c78cc-9adb-475e-9ec6-728bea81da14"
   },
   "outputs": [],
   "source": [
    "!python train.py --data_config data.yaml --epochs 5 --model_name yolov8n.pt --export_format onnx --onnx_path model.onnx --pt_path model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b61cb0",
   "metadata": {},
   "source": [
    "## Epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42bb17d4-0fe2-482c-b310-b826da49477c",
   "metadata": {
    "id": "42bb17d4-0fe2-482c-b310-b826da49477c",
    "outputId": "2eeb8da0-a723-4001-b966-2125327fb9c5"
   },
   "outputs": [],
   "source": [
    "!python train.py --data_config data.yaml --epochs 10 --model_name yolov8n.pt --export_format onnx --onnx_path model.onnx --pt_path model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6ef81",
   "metadata": {},
   "source": [
    "## Epoch 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef44614",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data_config data.yaml --epochs 15 --model_name yolov8n.pt --export_format onnx --onnx_path model.onnx --pt_path model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82676d9",
   "metadata": {},
   "source": [
    "## Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data_config data.yaml --epochs 20 --model_name yolov8n.pt --export_format onnx --onnx_path model.onnx --pt_path model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a4e19",
   "metadata": {},
   "source": [
    "# Train Batch 16 lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81629492",
   "metadata": {},
   "source": [
    "## Epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfcb4da-f61f-43ef-a3c8-a238d77f523d",
   "metadata": {
    "id": "fdfcb4da-f61f-43ef-a3c8-a238d77f523d",
    "outputId": "f55fe330-ced1-4576-e508-880192ab563e"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')  \n",
    "model.train(\n",
    "    data='data.yaml', \n",
    "    epochs=5,                   \n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.001,\n",
    "    pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab3f2c5",
   "metadata": {},
   "source": [
    "## Epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f161cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "model.train(\n",
    "    data=\"data.yaml\", \n",
    "    epochs=10,         \n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.001,\n",
    "    pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23690287",
   "metadata": {},
   "source": [
    "## Epoch 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e777e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8n.pt\")  \n",
    "\n",
    "model.train(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=15,               \n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.001,\n",
    "    pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa1626",
   "metadata": {},
   "source": [
    "## Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572759ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "model.train(\n",
    "    data=\"data.yaml\", \n",
    "    epochs=20,                      \n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.001,                  \n",
    "    pretrained=True,\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c455dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO('yolov8n.yaml')  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data='data.yaml',  # Path to the dataset configuration file\n",
    "    epochs=50,                        # Number of epochs to train\n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62216f0",
   "metadata": {},
   "source": [
    "# Train Batch 16 lr 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac397a68",
   "metadata": {},
   "source": [
    "## Epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=5,                          # Number of epochs to train\n",
    "    batch=16,\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,                      # Final learning rate\n",
    "    project=\"runs/detect/\"  # Path to save training results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a60db",
   "metadata": {},
   "source": [
    "## Epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=10,                          # Number of epochs to train\n",
    "    batch=16,\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,                      # Final learning rate\n",
    "    project=\"runs/detect/\"  # Path to save training results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447804bf",
   "metadata": {},
   "source": [
    "## Epochs 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=15,                          # Number of epochs to train\n",
    "    batch=16,\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,                      # Final learning rate\n",
    "    project=\"runs/detect/\"  # Path to save training results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad12fa",
   "metadata": {},
   "source": [
    "## Epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=20,                          # Number of epochs to train\n",
    "    batch=16,\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,                      # Final learning rate\n",
    "    project=\"runs/detect/\"  # Path to save training results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241240f7",
   "metadata": {},
   "source": [
    "# Train Batch 32 lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41519b",
   "metadata": {},
   "source": [
    "## Epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=5,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.001,                           # Initial learning rate\n",
    "    lrf=0.001,                            # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670afe3",
   "metadata": {},
   "source": [
    "## Epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=10,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.001,                           # Initial learning rate\n",
    "    lrf=0.001,                            # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6fe14",
   "metadata": {},
   "source": [
    "## Epochs 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=15,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.001,                           # Initial learning rate\n",
    "    lrf=0.001,                            # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cbd4c3",
   "metadata": {},
   "source": [
    "## Epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc63abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=20,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.001,                          # Initial learning rate\n",
    "    lrf=0.001,                          # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e65fef",
   "metadata": {},
   "source": [
    "# Train Batch 32 lr 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c39792",
   "metadata": {},
   "source": [
    "## Epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=5,                          # Number of epochs to train\n",
    "    batch=32,                          # Batch size\n",
    "    lr0=0.01,                          # Initial learning rate\n",
    "    lrf=0.01,                           # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e107d9",
   "metadata": {},
   "source": [
    "## Epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=10,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.01,                           # Initial learning rate\n",
    "    lrf=0.01,                            # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34b47f",
   "metadata": {},
   "source": [
    "## Epochs 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=15,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.01,                           # Initial learning rate\n",
    "    lrf=0.01,                           # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15c00d",
   "metadata": {},
   "source": [
    "## Epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ultralytics YOLO library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model or define your own custom model\n",
    "model = YOLO(\"yolov8n.yaml\")  # yolov8n.yaml is the configuration file for YOLOv8n\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=20,                          # Number of epochs to train\n",
    "    batch=32,                           # Batch size\n",
    "    lr0=0.01,                           # Initial learning rate\n",
    "    lrf=0.01,                           # Final learning rate\n",
    "    project=\"runs/detect/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97c762",
   "metadata": {},
   "source": [
    "# Prediksi Citra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dd08120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "best_model_path = 'runs/detect/train2/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# Define the path to your testing images\n",
    "test_images_path = 'dataset/test/images'  # Adjust this path as needed\n",
    "\n",
    "# Make predictions on the test images and save the results with confidence threshold of 0.5\n",
    "results = model.predict(\n",
    "    source=test_images_path,\n",
    "    save=True,\n",
    "    conf=0.3,\n",
    "    project='predict/epoch10_batch16_lr0.001/'\n",
    ")\n",
    "\n",
    "# Display prediction results\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "print(\"Predictions have been saved to the specified directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb32d32",
   "metadata": {},
   "source": [
    "# Hasil Prediksi Citra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93f772df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tentukan path direktori\n",
    "directory = \"predict/epoch10_batch16_lr0.001/predict\"\n",
    "\n",
    "# List semua file dalam direktori\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Pilih semua path gambar dari direktori\n",
    "image_paths = [os.path.join(directory, file) for file in files if file.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "# Fungsi untuk memuat dan menampilkan gambar\n",
    "def plot_and_save_images(image_paths, output_path):\n",
    "    num_images = len(image_paths)\n",
    "    cols = 4\n",
    "    rows = (num_images + cols - 1) // cols  # Menghitung jumlah baris yang diperlukan\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img_path, ax in zip(image_paths, axes):\n",
    "        # Muat gambar menggunakan cv2\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Konversi dari BGR ke RGB (opencv menggunakan BGR secara default)\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Nonaktifkan sumbu untuk kotak kosong\n",
    "    for ax in axes[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Simpan gambar hasil prediksi dalam satu file\n",
    "    fig.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)  # Tutup figure setelah menyimpannya\n",
    "\n",
    "# Bagi path gambar menjadi tiga bagian\n",
    "split_size = len(image_paths) // 3\n",
    "image_paths1 = image_paths[:split_size]\n",
    "image_paths2 = image_paths[split_size:2*split_size]\n",
    "image_paths3 = image_paths[2*split_size:]\n",
    "\n",
    "# Panggil fungsi plot_and_save_images untuk menampilkan dan menyimpan gambar dalam tiga file terpisah\n",
    "plot_and_save_images(image_paths1, output_path=\"combined_image_part1.jpg\")\n",
    "plot_and_save_images(image_paths2, output_path=\"combined_image_part2.jpg\")\n",
    "plot_and_save_images(image_paths3, output_path=\"combined_image_part3.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2f640",
   "metadata": {},
   "source": [
    "# Deteksi Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6335a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\") \n",
    "\n",
    "image_folder = \"dataset/test/images\"\n",
    "\n",
    "output_folder = \"detect/epoch10_batch16_lr0.001/\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "display_width = 500\n",
    "display_height = 700\n",
    "image_files = [\n",
    "    os.path.join(image_folder, f)\n",
    "    for f in os.listdir(image_folder)\n",
    "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "]\n",
    "\n",
    "if not image_files:\n",
    "    print(\"Tidak ada gambar ditemukan di folder.\")\n",
    "    exit()\n",
    "\n",
    "confidence_threshold = 0.32\n",
    "iou_threshold = 0.3\n",
    "\n",
    "class_labels = {\n",
    "    0: \"atasan_sesuai\",\n",
    "    1: \"atasan_tidak_sesuai\",\n",
    "    2: \"bawahan_sesuai\",\n",
    "    3: \"bawahan_tidak_sesuai\",\n",
    "    4: \"alas_kaki_sesuai\",\n",
    "    5: \"alas_kaki_tidak_sesuai\"\n",
    "}\n",
    "\n",
    "class_colors = {\n",
    "    \"atasan_sesuai\": (0, 128, 0),  \n",
    "    \"bawahan_sesuai\": (0, 128, 0),  \n",
    "    \"alas_kaki_sesuai\": (0, 128, 0),\n",
    "    \"atasan_tidak_sesuai\": (0, 0, 255),  \n",
    "    \"bawahan_tidak_sesuai\": (0, 0, 255), \n",
    "    \"alas_kaki_tidak_sesuai\": (0, 0, 255),  \n",
    "}\n",
    "\n",
    "for image_path in image_files:\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Gagal memuat gambar: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    results = model(image, conf=confidence_threshold)\n",
    "\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        print(f\"Tidak ada objek terdeteksi di gambar: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    boxes_nms = [[x1, y1, x2 - x1, y2 - y1] for x1, y1, x2, y2 in boxes]\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        boxes_nms, confidences.tolist(), score_threshold=confidence_threshold, nms_threshold=iou_threshold\n",
    "    )\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x1, y1, x2, y2 = map(int, boxes[i])\n",
    "            class_id = int(classes[i])\n",
    "            label = class_labels.get(class_id, \"Tidak Dikenal\")\n",
    "            color = class_colors.get(label, (255, 255, 255)) \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)\n",
    "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)  \n",
    "\n",
    "    image_resized = cv2.resize(image, (display_width, display_height))\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, image_resized)\n",
    "    print(f\"Hasil disimpan di: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Load model terbaik\n",
    "best_model_path = 'runs/detect/train3/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# 2. Path gambar uji\n",
    "test_images_path = 'dataset/test/images'\n",
    "output_folder = 'predicted_images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 3. Mapping class ID ke label\n",
    "class_labels = {\n",
    "    0: \"atasan_sesuai\",\n",
    "    1: \"atasan_tidak_sesuai\",\n",
    "    2: \"bawahan_sesuai\",\n",
    "    3: \"bawahan_tidak_sesuai\",\n",
    "    4: \"alas_kaki_sesuai\",\n",
    "    5: \"alas_kaki_tidak_sesuai\"\n",
    "}\n",
    "\n",
    "# 4. Kategori label\n",
    "label_sesuai = {\"atasan_sesuai\", \"bawahan_sesuai\", \"alas_kaki_sesuai\"}\n",
    "label_tidak_sesuai = {\"atasan_tidak_sesuai\", \"bawahan_tidak_sesuai\", \"alas_kaki_tidak_sesuai\"}\n",
    "\n",
    "# 5. Fungsi ambil warna dan ketebalan garis\n",
    "def get_color_and_thickness(label):\n",
    "    if label in label_tidak_sesuai:\n",
    "        return (0, 0, 255), 4  # Merah tebal\n",
    "    elif label in label_sesuai:\n",
    "        return (0, 255, 0), 2  # Hijau tipis\n",
    "    else:\n",
    "        return (255, 255, 255), 1  # Putih default\n",
    "\n",
    "# 6. Ambil semua file gambar\n",
    "image_files = [\n",
    "    os.path.join(test_images_path, f)\n",
    "    for f in os.listdir(test_images_path)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "# 7. Threshold deteksi\n",
    "confidence_threshold = 0.32\n",
    "\n",
    "# 8. Looping untuk prediksi tiap gambar\n",
    "for image_path in image_files:\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Gagal membuka gambar: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    results = model(image, conf=confidence_threshold)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is None or boxes.cls is None:\n",
    "        print(f\"Tidak ada deteksi pada {image_path}\")\n",
    "        continue\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        class_id = int(box.cls[0])\n",
    "        label = class_labels.get(class_id, \"tidak_dikenal\")\n",
    "\n",
    "        color, thickness = get_color_and_thickness(label)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Simpan hasil\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Hasil disimpan di: {output_path}\")\n",
    "\n",
    "    # Tampilkan dengan matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(f\"Deteksi: {os.path.basename(image_path)}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "764b10b2-7007-4815-ac85-d19050dfd619",
    "a9ae72a8-c996-41a0-b330-4233d46e39ef",
    "006e976e-fc1e-4392-8883-615faa601537",
    "9acb8af4-4236-441a-a2c3-810d7516bb36",
    "d26fd40c-03ff-4c04-8499-a6daa641cffd",
    "8f7d0f32-8b4a-48d6-9148-c9f02b64e98c",
    "FZJfgJeDyOAK",
    "190d2548-f350-43c8-bca2-4db1681094ed",
    "52237f6b-3bcf-40bf-800a-53c3bca20259",
    "ac7d05d4-1c05-411b-9b8a-11e74f850f92",
    "ad372acb-0e59-4951-ad2b-33dbc23ea519"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
